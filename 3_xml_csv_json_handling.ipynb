{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML_CSV_JSON handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Playing with CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Areas of usage of CSV\n",
    "# importing and exporting customer data\n",
    "# importing and exporting products\n",
    "# exporting orders\n",
    "# exporting e-commerce analytic reports  \n",
    "\n",
    "########################################################\n",
    "\n",
    "# The CSV module has several functions and classes available for reading and writing\n",
    "# CSVs, and they include:\n",
    "# csv.reader function\n",
    "# csv.writer function\n",
    "# csv.Dictwriter class\n",
    "# csv.DictReader class\n",
    "\n",
    "##########################################################\n",
    "#more details in e:\\day5\\notes\\csv pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_csv.reader'>\n",
      "['S No', 'Roll No', 'Student Name', 'Status', 'Marks1', 'Marks2', 'Marks3', 'Marks4', 'Marks5', 'Marks6', 'Total', 'Theory Total', 'Threory %', 'Sem %', 'CP']\n",
      "['1', '1601710029', 'Pratiksha Chauhan', 'Regular', '44', '47', '51', '53', '64', '59', '881', '318', '75.71', '88.1', '0']\n",
      "['2', '1601710050', 'Shaifali Singh ', 'Regular', '55', '42', '61', '45', '63', '53', '872', '319', '75.95', '87.2', '0']\n",
      "['3', '1601710015', 'Dishi Khanna', 'Regular', '45', '63', '51', '58', '50', '63', '869', '330', '78.57', '86.9', '0']\n",
      "['4', '1601710030', 'Km Priya Rani ', 'Regular', '47', '47', '56', '50', '62', '50', '863', '312', '74.29', '86.3', '0']\n",
      "['5', '1601710024', 'Km. Kamakshi Chanchal ', 'Regular', '36', '51', '50', '50', '53', '61', '854', '301', '71.67', '85.4', '0']\n",
      "['6', '1601710033', 'Km Tanya  Singh', 'Regular', '53', '42', '56', '44', '60', '54', '849', '309', '73.57', '84.9', '0']\n",
      "['7', '1601710025', 'Kanika Bhardwaj', 'Regular', '22', '37', '55', '46', '58', '59', '831', '277', '65.95', '83.1', '0']\n",
      "['8', '1601710007', 'Ashna Singh ', 'Regular', '39', '47', '51', '55', '42', '50', '826', '284', '67.62', '82.6', '0']\n",
      "['9', '1601710058', 'Vardan Vishnoi', 'Regular', '37', '40', '61', '49', '42', '47', '819', '276', '65.71', '81.9', '0']\n",
      "['10', '1601710011', 'Bhuvneshwari', 'Regular', '39', '51', '30', '45', '45', '54', '811', '264', '62.86', '81.1', '0']\n",
      "['11', '1601710027', 'Km. Nishtha Saxena', 'Regular', '43', '43', '32', '43', '56', '57', '798', '274', '65.24', '79.8', '0']\n",
      "['12', '1601710021', 'Km. Bhumika Rajput', 'Regular', '38', '51', '27', '44', '52', '40', '791', '252', '60', '79.1', '0']\n",
      "['13', '1601710034', 'Manu Saini', 'Regular', '30', '50', '34', '36', '51', '48', '785', '249', '59.29', '78.5', '0']\n",
      "['14', '1601710040', 'Nischal Bandhu', 'Regular', '39', '38', '34', '47', '43', '56', '781', '257', '61.19', '78.1', '0']\n",
      "['15', '1601710008', 'Avibhav Choudhary', 'Regular', '41', '50', '38', '38', '38', '50', '779', '255', '60.71', '77.9', '0']\n",
      "['16', '1601710046', 'Ripu Daman Singh', 'Regular', '39', '50', '41', '48', '41', '42', '775', '261', '62.14', '77.5', '0']\n",
      "['17', '1601710016', 'Ezan Abdullah', 'Regular', '47', '50', '50', '38', '24', '53', '771', '262', '62.38', '77.1', '0']\n",
      "['18', '1601710020', 'Km. Aparna', 'Regular', '36', '43', '42', '48', '38', '49', '769', '256', '60.95', '76.9', '0']\n",
      "['19', '1601710022', 'Km. Dhairya Singh ', 'Regular', '37', '45', '28', '47', '46', '53', '764', '256', '60.95', '76.4', '0']\n",
      "['20', '1601710004', 'Anant Tomar', 'Regular', '28', '44', '44', '38', '48', '50', '761', '252', '60', '76.1', '0']\n",
      "['21', '1601710051', 'Sheffali Barola ', 'Regular', '35', '25', '47', '42', '51', '40', '761', '240', '57.14', '76.1', '0']\n",
      "['22', '1601710019', 'Jatin Singh ', 'Regular', '36', '43', '24', '48', '43', '50', '756', '244', '58.1', '75.6', '0']\n",
      "['23', '1601710036', 'Mohd Sarfaraz Khan', 'Regular', '31', '45', '51', '49', '37', '56', '755', '269', '64.05', '75.5', '0']\n",
      "['24', '1601710009', 'Aviraj', 'Regular', '33', '49', '36', '55', '45', '47', '750', '265', '63.1', '75', '0']\n",
      "['25', '1601710048', 'Rudra Dutt Sharma', 'Regular', '36', '32', '26', '42', '26', '40', '740', '202', '48.1', '74', '0']\n",
      "['26', '1601710037', 'Mohit Rajput', 'Regular', '26', '23', '39', '49', '42', '50', '726', '229', '54.52', '72.6', '0']\n",
      "['27', '1601710013', 'Deepanshu Rajput', 'Regular', '30', '36', '23', '51', '48', '51', '722', '239', '56.9', '72.2', '0']\n",
      "['28', '1601710003', 'Km. Anam', 'Regular', '28', '31', '42', '46', '46', '46', '721', '239', '56.9', '72.1', '0']\n",
      "['29', '1601710031', 'Km. Shagun Rani', 'Regular', '32', '33', '43', '46', '42', '47', '720', '243', '57.86', '72', '0']\n",
      "['30', '1601710012', 'Chandrajeet Yadav', 'Regular', '26', '22', '27', '36', '38', '51', '718', '200', '47.62', '71.8', '0']\n",
      "['31', '1601710045', 'Razi Iqbal', 'Regular', '36', '43', '22', '55', '28', '45', '711', '229', '54.52', '71.1', '0']\n",
      "['32', '1601710035', 'Mohd Amaan', 'Regular', '28', '47', '41', '40', '38', '46', '708', '240', '57.14', '70.8', '0']\n",
      "['33', '1601710049', 'Samarth Mehrotra', 'Regular', '44', '47', '23', '41', '33', '33', '704', '221', '52.62', '70.4', '0']\n",
      "['34', '1601710052', 'Sparsh Agarwal', 'Regular', '36', '23', '41', '36', '41', '44', '704', '221', '52.62', '70.4', '0']\n",
      "['35', '1601710010', 'Ayush Sharma', 'Regular', '34', '33', '26', '46', '44', '35', '696', '218', '51.9', '69.6', '0']\n",
      "['36', '1601710056', 'Tanuj Kumar', 'Regular', '42', '42', '30', '39', '42', '42', '696', '237', '56.43', '69.6', '0']\n",
      "['37', '1601710002', 'Akshay Kumar', 'Regular', '23', '23', '38', '34', '40', '52', '689', '210', '50', '68.9', '0']\n",
      "['38', '1601710001', 'Abhinav Kumar', 'Regular', '23', '47', '28', '44', '24', '26', '683', '192', '45.71', '68.3', '0']\n",
      "['39', '1701710901', 'KM SANDHYA RANI', 'Regular', '22', '39', '24', '45', '38', '47', '678', '215', '51.19', '67.8', '0']\n",
      "['40', '1601710023', 'Km. Kalpana', 'Regular', '28', '24', '26', '35', '38', '50', '669', '201', '47.86', '66.9', '0']\n",
      "['41', '1601710055', 'Surya Pratap Singh Mahiyan', 'Regular', '32', '49', '29', '36', '34', '28', '661', '208', '49.52', '66.1', '0']\n",
      "['42', '1601710057', 'Udit Mishra', 'Regular', '21', '21', '26', '36', '38', '42', '638', '184', '43.81', '63.8', '0']\n",
      "['43', '1601710018', 'Harsh Pratap Singh ', 'Regular', '27', '44', '34', '29', '26', '42', '636', '202', '48.1', '63.6', '0']\n",
      "['44', '1701710902', 'SANDEEP KUMAR SISODIA', 'Regular', '22', '34', '30', '32', '26', '23', '613', '167', '39.76', '61.3', '0']\n",
      "['45', '1601710014', 'Dhruv Narayan Tiwari', 'Regular', '39', '46', '23', '51', '41', '20', '731', '220', '52.38', '73.1', '1']\n",
      "['46', '1601710028', 'Km Pratiksha Rajput', 'Regular', '35', '51', '9', '54', '29', '51', '710', '229', '54.52', '71', '1']\n",
      "['47', '1601710026', 'Km Neha', 'Regular', '27', '31', '11', '46', '52', '49', '687', '216', '51.43', '68.7', '1']\n",
      "['48', '1601710032', 'Km. Swati Rani', 'Regular', '33', '37', '9', '43', '27', '52', '685', '201', '47.86', '68.5', '1']\n",
      "['49', '1601710047', 'Rishab Bhardwaj', 'Regular', '28', '29', '11', '45', '22', '39', '663', '174', '41.43', '66.3', '1']\n",
      "['50', '1601710005', 'Apoorv Agarwal', 'Regular', '21', '26', '17', '32', '38', '50', '661', '184', '43.81', '66.1', '1']\n",
      "['51', '1601710053', 'Sudhanshu', 'Regular', '33', '29', '8', '37', '23', '21', '574', '151', '35.95', '57.4', '1']\n",
      "['52', '1601710038', 'Navneet Goutam', 'Regular', '18', '46', '7', '51', '42', '42', '671', '206', '49.05', '67.1', '2']\n",
      "['53', '1601710006', 'Ashish Kumar', 'Regular', '25', '16', '19', '37', '46', '31', '635', '174', '41.43', '63.5', '2']\n",
      "['54', '1601710039', 'Nikhil Rajput', 'Regular', '5', '21', '24', '45', '23', '48', '582', '166', '39.52', '58.2', '2']\n",
      "['55', '1601710041', 'Nishant Rajput', 'Regular', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', '236', '0', '0', '23.6', '10']\n",
      "['56', '1601710059', 'Vishal Kumar', 'Regular', 'ABS', '24', '22', '31', '22', '22', '359', '121', '28.81', '35.9', 'IN']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#usage of----- csv.reader module\n",
    "import csv      # the necessary module to play with csv\n",
    "with open('./example_csv/first.csv', newline='') as mycsvFile:  #syntax to open csv file \n",
    "    csvData = csv.reader(mycsvFile)    #reading data into csvData\n",
    "    print(type(csvData))\n",
    "    for row in csvData:\n",
    "        print(row)\n",
    "print(type(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S No', 'Roll No', 'Student Name']\n",
      "['1', '1601710029', 'Pratiksha Chauhan']\n",
      "['2', '1601710050', 'Shaifali Singh ']\n",
      "['3', '1601710015', 'Dishi Khanna']\n"
     ]
    }
   ],
   "source": [
    "#reading a small file to show usage of csv.writer\n",
    "import csv\n",
    "with open(\"./example_csv/second.csv\") as mycvsSecond:\n",
    "    csvData1=csv.reader(mycvsSecond)\n",
    "    for data in csvData1:\n",
    "        print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing complete\n"
     ]
    }
   ],
   "source": [
    "#writing new data to second.csv using csv.writer\n",
    "import csv\n",
    "new_data=[['6', '1601710060', 'Aman Kumar'],['7', '1601710058', 'Aman Kumar Choudhary']]\n",
    "myfile=open('./example_csv/second.csv','a', newline='')\n",
    "with myfile:\n",
    "    writer=csv.writer(myfile)\n",
    "    writer.writerows(new_data)\n",
    "print('Writing complete')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Data to write to CSV Roll No and Name\n",
      "Enter Roll no:23454\n",
      "Enter Name:xcd\n",
      "Writing complete\n",
      "wnat to enter more:y\n",
      "Enter Data to write to CSV Roll No and Name\n",
      "Enter Roll no:1212212\n",
      "Enter Name:anam\n",
      "Writing complete\n",
      "wnat to enter more:n\n"
     ]
    }
   ],
   "source": [
    "#making writing dynamic to the CSV file using csv.writer\n",
    "\n",
    "import csv\n",
    "def csv_write():\n",
    "    counter=0\n",
    "    ch='y'\n",
    "    while(ch=='y'):\n",
    "        print(\"Enter Data to write to CSV Roll No and Name\")\n",
    "        item1=input(\"Enter Roll no:\")\n",
    "        item2=input(\"Enter Name:\")\n",
    "        with open('./example_csv/second.csv','r') as myfile:\n",
    "            exist_data=csv.reader(myfile)\n",
    "            for row in exist_data:\n",
    "                counter+=1\n",
    "        new_data=[[counter,item1,item2]]\n",
    "\n",
    "        myfile=open('./example_csv/second.csv','a', newline='')\n",
    "        with myfile:\n",
    "            writer=csv.writer(myfile)\n",
    "            writer.writerows(new_data)\n",
    "        print('Writing complete')\n",
    "        ch=input('Enter y to insert more:')\n",
    "csv_write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6', '1601710060', 'Aman Kumar']\n",
      "['6', '1601710060', 'Aman Kumar']\n",
      "['7', '1601710058', 'Aman Kumar Choudhary']\n",
      "['6', '1601710060', 'Aman Kumar']\n",
      "['7', '1601710058', 'Aman Kumar Choudhary']\n",
      "['5', '1234567', 'xyz']\n",
      "['6', '23454', 'xcd']\n",
      "['13', '1212212', 'anam']\n"
     ]
    }
   ],
   "source": [
    "#read file again to check newly writed text\n",
    "\n",
    "with open('./example_csv/second.csv') as readFile:\n",
    "    row_data=csv.reader(readFile)\n",
    "    for row in row_data:\n",
    "        print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a csv using csv.Dictwriter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': '1601710029'}\n",
      "{'2': '1601710050'}\n",
      "{'3': '1601710015'}\n",
      "{'4': '1601710030'}\n",
      "{'5': '1601710024'}\n",
      "{'6': '1601710033'}\n",
      "{'7': '1601710025'}\n",
      "{'8': '1601710007'}\n",
      "{'9': '1601710058'}\n",
      "{'10': '1601710011'}\n",
      "{'11': '1601710027'}\n",
      "{'12': '1601710021'}\n",
      "{'13': '1601710034'}\n",
      "{'14': '1601710040'}\n",
      "{'15': '1601710008'}\n",
      "{'16': '1601710046'}\n",
      "{'17': '1601710016'}\n",
      "{'18': '1601710020'}\n",
      "{'19': '1601710022'}\n",
      "{'20': '1601710004'}\n",
      "{'21': '1601710051'}\n",
      "{'22': '1601710019'}\n",
      "{'23': '1601710036'}\n",
      "{'24': '1601710009'}\n",
      "{'25': '1601710048'}\n",
      "{'26': '1601710037'}\n",
      "{'27': '1601710013'}\n",
      "{'28': '1601710003'}\n",
      "{'29': '1601710031'}\n",
      "{'30': '1601710012'}\n",
      "{'31': '1601710045'}\n",
      "{'32': '1601710035'}\n",
      "{'33': '1601710049'}\n",
      "{'34': '1601710052'}\n",
      "{'35': '1601710010'}\n",
      "{'36': '1601710056'}\n",
      "{'37': '1601710002'}\n",
      "{'38': '1601710001'}\n",
      "{'39': '1701710901'}\n",
      "{'40': '1601710023'}\n",
      "{'41': '1601710055'}\n",
      "{'42': '1601710057'}\n",
      "{'43': '1601710018'}\n",
      "{'44': '1701710902'}\n",
      "{'45': '1601710014'}\n",
      "{'46': '1601710028'}\n",
      "{'47': '1601710026'}\n",
      "{'48': '1601710032'}\n",
      "{'49': '1601710047'}\n",
      "{'50': '1601710005'}\n",
      "{'51': '1601710053'}\n",
      "{'52': '1601710038'}\n",
      "{'53': '1601710006'}\n",
      "{'54': '1601710039'}\n",
      "{'55': '1601710041'}\n",
      "{'56': '1601710059'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('./example_csv/first.csv','r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        print({row['S_No']:row['Roll_No']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('sno', '6'), ('roll', '1601710060'), ('name', 'Aman Kumar')]), OrderedDict([('sno', '6'), ('roll', '1601710060'), ('name', 'Aman Kumar')]), OrderedDict([('sno', '7'), ('roll', '1601710058'), ('name', 'Aman Kumar Choudhary')]), OrderedDict([('sno', '6'), ('roll', '1601710060'), ('name', 'Aman Kumar')]), OrderedDict([('sno', '7'), ('roll', '1601710058'), ('name', 'Aman Kumar Choudhary')]), OrderedDict([('sno', '5'), ('roll', '1234567'), ('name', 'xyz')]), OrderedDict([('sno', '6'), ('roll', '23454'), ('name', 'xcd')]), OrderedDict([('sno', '13'), ('roll', '1212212'), ('name', 'anam')])]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "output=[]\n",
    "with open('./example_csv/second.csv','r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        output.append(row)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing using csv.Dictwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written\n"
     ]
    }
   ],
   "source": [
    "#using writerow() method\n",
    "import csv\n",
    "with open('./example_csv/second.csv', 'a', newline='') as csvfile:  # without newline='' it will write one blank \n",
    "    fieldnames = ['Sno', 'roll', 'name']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    #writer.writeheader() #if want to write to a newly created csv with header than use this function, it will write header also\n",
    "    writer.writerow({'Sno': '778', 'roll': 'Alex', 'name': 'Brian'})\n",
    "print('written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written\n"
     ]
    }
   ],
   "source": [
    "#using writerows() method #writerows is always used to write all rows data at once\n",
    "import csv\n",
    "with open('./example_csv/second.csv', 'a', newline='') as csvfile:  # without newline='' it will write one blank \n",
    "    fieldnames = ['Sno', 'roll', 'name']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    #writer.writeheader() #if want to write to a newly created csv with header than use this function, it will write header also\n",
    "    writer.writerows([{'Sno': '8', 'roll': 'Alex', 'name': 'Brian'},\n",
    "                     {'Sno': '9', 'roll': 'Alex', 'name': 'Brian'},\n",
    "                     {'Sno': '10', 'roll': 'Alex', 'name': 'Brian'}])\n",
    "print('written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('sno', '6'), ('roll', '1601710060'), ('name', 'Aman Kumar')]), OrderedDict([('sno', '6'), ('roll', '1601710060'), ('name', 'Aman Kumar')]), OrderedDict([('sno', '7'), ('roll', '1601710058'), ('name', 'Aman Kumar Choudhary')]), OrderedDict([('sno', '6'), ('roll', '1601710060'), ('name', 'Aman Kumar')]), OrderedDict([('sno', '7'), ('roll', '1601710058'), ('name', 'Aman Kumar Choudhary')]), OrderedDict([('sno', '5'), ('roll', '1234567'), ('name', 'xyz')]), OrderedDict([('sno', '6'), ('roll', '23454'), ('name', 'xcd')]), OrderedDict([('sno', '13'), ('roll', '1212212'), ('name', 'anam')]), OrderedDict([('sno', 'Sno'), ('roll', 'roll'), ('name', 'name')]), OrderedDict([('sno', 'B'), ('roll', 'Alex'), ('name', 'Brian')]), OrderedDict([('sno', 'B'), ('roll', 'Alex'), ('name', 'Brian')]), OrderedDict([('sno', 'B'), ('roll', 'Alex'), ('name', 'Brian')]), OrderedDict([('sno', '778'), ('roll', 'Alex'), ('name', 'Brian')]), OrderedDict([('sno', '778'), ('roll', 'Alex'), ('name', 'Brian')]), OrderedDict([('sno', '8'), ('roll', 'Alex'), ('name', 'Brian')]), OrderedDict([('sno', '9'), ('roll', 'Alex'), ('name', 'Brian')]), OrderedDict([('sno', '10'), ('roll', 'Alex'), ('name', 'Brian')]), OrderedDict([('sno', '8'), ('roll', 'Alex'), ('name', 'Brian')]), OrderedDict([('sno', '9'), ('roll', 'Alex'), ('name', 'Brian')]), OrderedDict([('sno', '10'), ('roll', 'Alex'), ('name', 'Brian')])]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "output=[]\n",
    "with open('./example_csv/second.csv','r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        output.append(row)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Over the last 5-10 years, the JSON (https://en.wikipedia.org/wiki/JSON) format has\\nbeen one of, if not the most, popular ways to serialize data. Especially in the web\\ndevelopment world, you'll likely encounter JSON through one of the many REST\\nAPIs (https://en.wikipedia.org/wiki/Representational_state_transfer), application\\ncon\\U0010007dguration, or even simple data storage.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Over the last 5-10 years, the JSON (https://en.wikipedia.org/wiki/JSON) format has\n",
    "been one of, if not the most, popular ways to serialize data. Especially in the web\n",
    "development world, you'll likely encounter JSON through one of the many REST\n",
    "APIs (https://en.wikipedia.org/wiki/Representational_state_transfer), application\n",
    "con􀁽guration, or even simple data storage.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing JSON to a File\n",
    "# The easiest way to write your data in the JSON format to a 􀁽le using Python is to\n",
    "# use store your data in a dict object, which can contain other nested dict s,\n",
    "# arrays, booleans, or other primitive types like integers and strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing JSON to a File in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JSONDecodeError', 'JSONDecoder', 'JSONEncoder', '__all__', '__author__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_default_decoder', '_default_encoder', 'codecs', 'decoder', 'detect_encoding', 'dump', 'dumps', 'encoder', 'load', 'loads', 'scanner']\n",
      "Help on function dump in module json:\n",
      "\n",
      "dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)\n",
      "    Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n",
      "    ``.write()``-supporting file-like object).\n",
      "    \n",
      "    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
      "    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
      "    instead of raising a ``TypeError``.\n",
      "    \n",
      "    If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n",
      "    contain non-ASCII characters if they appear in strings contained in\n",
      "    ``obj``. Otherwise, all such characters are escaped in JSON strings.\n",
      "    \n",
      "    If ``check_circular`` is false, then the circular reference check\n",
      "    for container types will be skipped and a circular reference will\n",
      "    result in an ``OverflowError`` (or worse).\n",
      "    \n",
      "    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
      "    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n",
      "    in strict compliance of the JSON specification, instead of using the\n",
      "    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
      "    \n",
      "    If ``indent`` is a non-negative integer, then JSON array elements and\n",
      "    object members will be pretty-printed with that indent level. An indent\n",
      "    level of 0 will only insert newlines. ``None`` is the most compact\n",
      "    representation.\n",
      "    \n",
      "    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
      "    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
      "    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
      "    you should specify ``(',', ':')`` to eliminate whitespace.\n",
      "    \n",
      "    ``default(obj)`` is a function that should return a serializable version\n",
      "    of obj or raise TypeError. The default simply raises TypeError.\n",
      "    \n",
      "    If *sort_keys* is true (default: ``False``), then the output of\n",
      "    dictionaries will be sorted by key.\n",
      "    \n",
      "    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
      "    ``.default()`` method to serialize additional types), specify it with\n",
      "    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dir(json))\n",
    "help(json.dump)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#creating json object\n",
    "data = {}\n",
    "data['people'] = []\n",
    "data['people'].append({\n",
    "'name': 'Scott',\n",
    "'website': 'stackabuse.com (http://stackabuse.com)',\n",
    "'from': 'Nebraska'\n",
    "})\n",
    "data['people'].append({\n",
    "'name': 'Larry',\n",
    "'website': 'google.com (http://google.com)',\n",
    "'from': 'Michigan'\n",
    "})\n",
    "data['people'].append({\n",
    "'name': 'Tim',\n",
    "'website': 'apple.com (http://apple.com)',\n",
    "'from': 'Alabama'\n",
    "})\n",
    "with open('data.txt', 'w') as outfile:\n",
    "    json.dump(data, outfile)    #writing json object to a txt file\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading JSON from a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "Name: Scott\n",
      "Website: stackabuse.com (http://stackabuse.com)\n",
      "From: Nebraska\n",
      "\n",
      "Name: Larry\n",
      "Website: google.com (http://google.com)\n",
      "From: Michigan\n",
      "\n",
      "Name: Tim\n",
      "Website: apple.com (http://apple.com)\n",
      "From: Alabama\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now read the above saved json file\n",
    "import json\n",
    "with open('data.txt','r') as json_file:\n",
    "    data = json.load(json_file) #to load data  into data dictionary\n",
    "    print(type(data))\n",
    "    for p in data['people']:\n",
    "        print('Name: ' + p['name'])\n",
    "        print('Website: ' + p['website'])\n",
    "        print('From: ' + p['from'])\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"people\": [\\n        {\\n            \"from\": \"Nebraska\",\\n            \"name\": \"Scott\",\\n            \"website\": \"stackabuse.com (http://stackabuse.com)\"\\n        }\\n    ]\\n}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formating with json to amke human redable\n",
    "import json\n",
    "data = {'people':[{'name': 'Scott', 'website': 'stackabuse.com (http://stackabuse.com)', 'from': 'Nebraska'}]}\n",
    "json.dumps(data, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading XML Documents\n",
    "Using minidom\n",
    ":-In order to parse an XML document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xml.dom.minicompat.NodeList'>\n"
     ]
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "# parse an xml file by name\n",
    "mydoc = minidom.parse('items.xml') #parsing of xml file\n",
    "items = mydoc.getElementsByTagName('item')   #getting values by elements\n",
    "print(type(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item #2 attribute:\n",
      "item2\n"
     ]
    }
   ],
   "source": [
    "#printing attributes \n",
    "# one specific item attribute\n",
    "print('Item #2 attribute:')\n",
    "print(items[1].attributes['name'].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All attributes:\n",
      "item1\n",
      "item2\n"
     ]
    }
   ],
   "source": [
    "# all item attributes\n",
    "print('\\nAll attributes:')\n",
    "for elem in items:\n",
    "    print(elem.attributes['name'].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item #2 data:\n",
      "item2abc\n",
      "item2abc\n"
     ]
    }
   ],
   "source": [
    "# one specific item's data\n",
    "print('\\nItem #2 data:')\n",
    "print(items[1].firstChild.data)\n",
    "print(items[1].childNodes[0].data) #two ways to print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All item data:\n",
      "item1abc\n",
      "item2abc\n"
     ]
    }
   ],
   "source": [
    "# all items data\n",
    "print('\\nAll item data:')\n",
    "for elem in items:\n",
    "    print(elem.firstChild.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ElementTree\n",
    "ElementTree presents us with an very simple way to process XML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Root: <Element 'data' at 0x0000000005591EA8>\n",
      "Item #1 attribute: {'name': 'item1'}\n",
      "\n",
      "All attributes:\n",
      "{'name': 'item1'}\n",
      "{'name': 'item2'}\n",
      "\n",
      "\n",
      "Value of one i.e. data\n",
      "Item #1 data: item1abc\n",
      "\n",
      "\n",
      " data for all items\n",
      "item1abc\n",
      "item2abc\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "MyTree=ET.parse(\"items.xml\")\n",
    "root=MyTree.getroot()\n",
    "print(\"Printing Root:\",root)\n",
    "#will print <Element 'data' at 0x000000000570E638>    ---as the root is <data>\n",
    "\n",
    "################### ######################################################################\n",
    "#now print the first attribute\n",
    "# one specific item attribute\n",
    "print('Item #1 attribute:',root[0][0].attrib)\n",
    "\n",
    "\n",
    "#####################################################################3\n",
    "#print all-----# all item attributes\n",
    "print('\\nAll attributes:')\n",
    "for elem in root:\n",
    "    for subelem in elem:\n",
    "        print(subelem.attrib)\n",
    "        \n",
    "###############################################################################\n",
    "print(\"\\n\\nValue of one i.e. data\")\n",
    "print(\"Item #1 data:\", root[0][0].text)\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################3\n",
    "print(\"\\n\\n data for all items\")\n",
    "for item in root:\n",
    "    for subitem in item:\n",
    "        print(subitem.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting length of total items using minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "\n",
    "data=minidom.parse(\"items.xml\")\n",
    "myDom=data.getElementsByTagName('item')   #getting all items using tagname\n",
    "len(myDom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get length using Element Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "MyTree=ET.parse('items.xml')\n",
    "root=MyTree.getroot()\n",
    "len(root[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing XML using Element Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The steps are:\\n1. Create an element, which will act as our root element. In our case the tag for\\nthis element is \"data\".\\n\\n\\n2. Once we have our root element, we can create sub-elements by using the\\nSubElement function. This function has the syntax:\\nSubElement(parent, tag, attrib={}, **extra)\\nHere parent is the parent node to connect to, attrib is a dictionary\\ncontaining the element attributes, and extra are additional keyword\\narguments. This function returns an element to us, which can be used to\\nattach other sub-elements, as we do in the following lines by passing items to\\nthe SubElement constructor.\\n3. Although we can add our attributes with the SubElement function, we can\\nalso use the set() function, as we do in the following code. The element text\\nis created with the text property of the Element object.\\n4. In the last 3 lines of the code below we create a string out of the XML tree, and\\nwe write that data to a \\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''The steps are:\n",
    "1. Create an element, which will act as our root element. In our case the tag for\n",
    "this element is \"data\".\\n\n",
    "\n",
    "2. Once we have our root element, we can create sub-elements by using the\n",
    "SubElement function. This function has the syntax:\n",
    "SubElement(parent, tag, attrib={}, **extra)\n",
    "Here parent is the parent node to connect to, attrib is a dictionary\n",
    "containing the element attributes, and extra are additional keyword\n",
    "arguments. This function returns an element to us, which can be used to\n",
    "attach other sub-elements, as we do in the following lines by passing items to\n",
    "the SubElement constructor.\n",
    "3. Although we can add our attributes with the SubElement function, we can\n",
    "also use the set() function, as we do in the following code. The element text\n",
    "is created with the text property of the Element object.\n",
    "4. In the last 3 lines of the code below we create a string out of the XML tree, and\n",
    "we write that data to a file we open.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "#create xml file structure\n",
    "data = ET.Element('student')\n",
    "items = ET.SubElement(data, 'singlestudent')\n",
    "item1 = ET.SubElement(items, 'item')\n",
    "item2 = ET.SubElement(items, 'item')\n",
    "item1.set('name','Roll No')\n",
    "item2.set('name','Name')\n",
    "item1.text = '12340023'\n",
    "item2.text = 'Rohan'\n",
    "\n",
    "\n",
    "\n",
    "#create the xml file with the above structure\n",
    "mydata = ET.tostring(data, encoding=\"unicode\")    #coversion to string -- encoding=\"unicode\"  is must to write to convert to string\n",
    "print(type(mydata))\n",
    "myfile = open(\"items2.xml\", \"w\")\n",
    "\n",
    "myfile.write(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'student' at 0x0000000005293E08>\n",
      "<Element 'singlestudent' at 0x00000000052A8D18>\n",
      "{'name': 'item1'}\n",
      "item1abc\n",
      "{'name': 'item2'}\n",
      "item2abc\n"
     ]
    }
   ],
   "source": [
    "#parse to the items2.xml\n",
    "import xml.etree.ElementTree as ET\n",
    "mydata=ET.parse(\"items2.xml\")\n",
    "root=mydata.getroot()\n",
    "print(root)\n",
    "for items in root:\n",
    "    print(items)\n",
    "    for subitems in item:\n",
    "        print(subitems.attrib)\n",
    "        print(subitems.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding XML Elements\n",
    "Using ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find one\n",
      "item1\n",
      "find all\n",
      "{'name': 'item1'}\n",
      "item1\n",
      "{'name': 'item2'}\n",
      "item2\n"
     ]
    }
   ],
   "source": [
    "#findall()-----to find the specific element in tree with matches a specified criteria\n",
    "#the function find() , which returns only the first subelement that matches the specified criteria\n",
    "# findall(match, namespaces=None)\n",
    "# find(match, namespaces=None)\n",
    "\n",
    "#In addition, there is another helper function that returns the text of the \n",
    "#findtext(match, default=None, namespaces=None)\n",
    "\n",
    "#example\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('items.xml')\n",
    "root = tree.getroot()\n",
    "# find the first 'item' object\n",
    "print('find one')\n",
    "for elem in root:\n",
    "    print(elem.find('item').get('name'))\n",
    "    \n",
    "    \n",
    "#find all\n",
    "print('find all')\n",
    "for elem in root:\n",
    "    for subelem in elem.findall('item'):\n",
    "# if we don't need to know the name of the attribute(s), get the dict\n",
    "        print(subelem.attrib)\n",
    "        print(subelem.get('name')) #if we know the name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying XML Elements\n",
    "using ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('items.xml')\n",
    "root = tree.getroot()\n",
    "# changing a field text\n",
    "for elem in root.iter('item'):\n",
    "    elem.text = 'new text'\n",
    "# modifying an attribute\n",
    "for elem in root.iter('item'):\n",
    "    elem.set('name', 'newitem')\n",
    "    \n",
    "# adding an attribute\n",
    "for elem in root.iter('item'):\n",
    "    elem.set('name2', 'newitem2')\n",
    "tree.write('newitems.xml')   #After running the code, the resulting XML have the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More details-----\n",
    "## 1.Creating new item\n",
    "## 2. Dleting a item and all ---refer extra material xml notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML , XHTML Parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#module html.parser and automatically get adapt when get compiled in python3\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered a start tag: html\n",
      "Encountered a start tag: head\n",
      "Encountered a start tag: title\n",
      "Encountered some data : Test\n",
      "Encountered an end tag : title\n",
      "Encountered an end tag : head\n",
      "Encountered a start tag: body\n",
      "Encountered a start tag: h1\n",
      "Encountered some data : Parse me!\n",
      "Encountered an end tag : h1\n",
      "Encountered an end tag : body\n",
      "Encountered an end tag : html\n"
     ]
    }
   ],
   "source": [
    "#As a basic example, below is a simple HTML parser that uses the HTMLParser class to print out\n",
    "#start tags, end tags and data as they are encountered:\n",
    "from html.parser import HTMLParser\n",
    "# create a subclass and override the handler methods\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        print (\"Encountered a start tag:\", tag)\n",
    "    def handle_endtag(self, tag):\n",
    "        print (\"Encountered an end tag :\", tag)\n",
    "    def handle_data(self, data):\n",
    "        print (\"Encountered some data :\", data)\n",
    "#create object or instanciate it and feed some HTML for practice\n",
    "parser = MyHTMLParser()   #creating object\n",
    "parser.feed('<html><head><title>Test</title></head>'\n",
    "'<body><h1>Parse me!</h1></body></html>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CDATA_CONTENT_ELEMENTS', '_HTMLParser__starttag_text', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_decl_otherchars', '_parse_doctype_attlist', '_parse_doctype_element', '_parse_doctype_entity', '_parse_doctype_notation', '_parse_doctype_subset', '_scan_name', 'check_for_whole_start_tag', 'clear_cdata_mode', 'close', 'error', 'feed', 'get_starttag_text', 'getpos', 'goahead', 'handle_charref', 'handle_comment', 'handle_data', 'handle_decl', 'handle_endtag', 'handle_entityref', 'handle_pi', 'handle_startendtag', 'handle_starttag', 'parse_bogus_comment', 'parse_comment', 'parse_declaration', 'parse_endtag', 'parse_html_declaration', 'parse_marked_section', 'parse_pi', 'parse_starttag', 'reset', 'set_cdata_mode', 'unescape', 'unknown_decl', 'updatepos']\n"
     ]
    }
   ],
   "source": [
    "print(dir(HTMLParser))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
